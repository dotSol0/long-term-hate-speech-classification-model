{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ffd0b6-de74-4db1-b3b3-02c583e34951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /usr/share/pip-wheels\n",
      "Requirement already satisfied: textblob in ./.local/lib/python3.11/site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from nltk>=3.8->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from nltk>=3.8->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from nltk>=3.8->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from nltk>=3.8->textblob) (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75990d03-b208-4beb-abea-0598c900d190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /usr/share/pip-wheels\n",
      "Requirement already satisfied: xgboost in ./.local/lib/python3.11/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in ./.local/lib/python3.11/site-packages (from xgboost) (2.23.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from xgboost) (1.11.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa43a8da-eb51-4326-9d7b-fe51ad88c50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /usr/share/pip-wheels\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from imbalanced-learn) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from imbalanced-learn) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from imbalanced-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "215521ce-43e8-4ce5-b056-c8287bc10e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c6bee24-cc8a-4384-87d2-ee447b2d0024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming, etc.\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk import pr\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9466469d-ed1e-489c-99bb-9d90c32101d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24783, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('twitter_data.csv') #Converts test data into a pandas dataframe\n",
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62b972b0-26c3-40d7-9e8c-fad055b4ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  labels  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...       2  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...       1  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...       1  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...       1  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...       1  \n"
     ]
    }
   ],
   "source": [
    "# Map the 'class' column values to corresponding labels\n",
    "df['labels'] = df['class'].map({\n",
    "    0: 0,      # Label for hate speech\n",
    "    1: 1, # Label for offensive language\n",
    "    2: 2  # Label for neutral speech\n",
    "})\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify the changes\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05c5fd74-de11-4820-9407-b9fc2a915215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither',\n",
      "       'class', 'tweet', 'labels'],\n",
      "      dtype='object')\n",
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  labels  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...       2  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...       1  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...       1  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...       1  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...       1  \n"
     ]
    }
   ],
   "source": [
    "print(df.columns)  # This will show all the column names\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e61ba356-de37-44b2-a27e-81f0ecce60f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m      text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(text)\n\u001b[1;32m     13\u001b[0m      \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[0;32m---> 14\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(clean) \u001b[38;5;66;03m#applies preprocessing to \"tweet\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def clean(text): #preproccessing function\n",
    "     text = str(text).lower()\n",
    "     text = re.sub('\\[.*?\\]', '', text)\n",
    "     text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "     text = re.sub('<.*?>+', '', text)\n",
    "     text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "     text = re.sub('\\n', '', text)\n",
    "     text = re.sub('\\w*\\d\\w*', '', text)\n",
    "     text = [word for word in text.split(' ') if word not in stopword]\n",
    "     text = \" \".join(text)\n",
    "     text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "     text = \" \".join(text)\n",
    "     return text\n",
    "df[\"tweet\"] = df[\"tweet\"].apply(clean) #applies preprocessing to \"tweet\" column of test/train dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "194faf6e-9135-48c9-a4a1-614f2c5ab8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  labels  sentiment  \n",
      "0   rt mayasolov woman shouldnt complain clean ho...       2   0.366667  \n",
      "1   rt  boy dat coldtyga dwn bad cuffin dat hoe  ...       1  -0.700000  \n",
      "2   rt urkindofbrand dawg rt  ever fuck bitch sta...       1  -0.300000  \n",
      "3             rt cganderson vivabas look like tranni       1   0.000000  \n",
      "4   rt shenikarobert shit hear might true might f...       1   0.075000  \n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Function to compute sentiment polarity\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "df['sentiment'] = df['tweet'].apply(get_sentiment)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba16f29a-1cb1-4475-8076-b1cd03aa4f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming df['tweet'] contains the text and df['labels'] contains the class labels\n",
    "\n",
    "# Convert the data into numpy arrays\n",
    "x = np.array(df[\"tweet\"])\n",
    "y = np.array(df[\"labels\"])\n",
    "\n",
    "# Step 1: CV\n",
    "cv = CountVectorizer(ngram_range=(1, 3))\n",
    "x = cv.fit_transform(x)  # Transforms the text data into CV feature matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2182e7d6-eb0b-4826-95e2-773df754af87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classifier Report for Class 0 vs. Rest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      7714\n",
      "           1       0.43      0.46      0.45       465\n",
      "\n",
      "    accuracy                           0.93      8179\n",
      "   macro avg       0.70      0.71      0.71      8179\n",
      "weighted avg       0.94      0.93      0.94      8179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a binary label for class 0\n",
    "y_binary = (y_train == 0).astype(int)  # 1 if class 0, else 0\n",
    "\n",
    "# Initialize a classifier for the binary task \n",
    "binary_clf = LogisticRegression(class_weight='balanced', random_state=42) # If one wants to test a different binary classifier model here, this is the code for Logistic Regression. Just replace Logistic Regression with the model of your choosing.\n",
    "binary_clf.fit(X_train, y_binary)\n",
    "\n",
    "# Evaluate the binary classifier on the test set\n",
    "y_binary_pred = binary_clf.predict(X_test)\n",
    "print(\"Binary Classifier Report for Class 0 vs. Rest:\")\n",
    "print(classification_report((y_test == 0).astype(int), y_binary_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee6145f2-807c-4add-8b98-986c948b4bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.53      0.46       465\n",
      "           1       0.96      0.86      0.91      6335\n",
      "           2       0.68      0.93      0.78      1379\n",
      "\n",
      "    accuracy                           0.86      8179\n",
      "   macro avg       0.68      0.77      0.72      8179\n",
      "weighted avg       0.88      0.86      0.86      8179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# If one wants to test a different multi-class classifier model here, this is the code for the RandomForest. Just replace RandomForest with the model of your choosing.\n",
    "clf_rf = RandomForestClassifier(\n",
    "    n_estimators=200, min_samples_split=2,\n",
    "    min_samples_leaf=1,max_depth=20, class_weight='balanced', random_state=42 #parameters\n",
    ")\n",
    "clf_rf.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "# Predict with the main multi-class classifier\n",
    "y_pred_main = clf_rf.predict(X_test)\n",
    "\n",
    "# Predict with the binary classifier focused on class 0\n",
    "y_pred_binary = binary_clf.predict(X_test)\n",
    "\n",
    "# Override predictions based on the binary classifier\n",
    "for i in range(len(y_pred_main)):\n",
    "    if y_pred_binary[i] == 1:  # If binary classifier predicts class 0\n",
    "        y_pred_main[i] = 0\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Combined Model Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfcabd0-3a3b-4ac6-a9d8-8ab66a836639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter tester for classifier\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, n_jobs=-1, scoring='f1_weighted')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "best_clf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66b3939a-d8c9-4648-84cb-4ace8ad31cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function applies the classifier to every tweet in a dataset and returns a dataframe with the text indices and their hate classifiers. \n",
    "def process_file_optimized(dft, name, batch_size=500): #dft takes in a pandas dataframe, name is a string, and batch_size indicates how much rows will be processed in each \n",
    "    output_list = []\n",
    "    num_rows = dft.shape[0]\n",
    "\n",
    "    for start in range(0, num_rows, batch_size):\n",
    "        end = min(start + batch_size, num_rows)\n",
    "        batch = dft[\"text\"][start:end]\n",
    "\n",
    "        # Vectorize and predict for the batch\n",
    "        transformed_data = cv.transform(batch)\n",
    "        rf_preds = clf_rf.predict(transformed_data)\n",
    "        binary_preds = binary_clf.predict(transformed_data)\n",
    "\n",
    "        # Combine predictions\n",
    "        output_list.extend([0 if binary_preds[i] == 1 else rf_preds[i] for i in range(len(rf_preds))])\n",
    "\n",
    "    # Create a DataFrame with the combined results\n",
    "    result_df = pd.DataFrame(output_list, columns=['Scores for ' + name])\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e04dbb67-1795-42a0-9432-ed9a790e5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorecalc(result_df): #this function takes a result dataframe and counts the 0s, 1s, and 2s of the dataframe. In other words, it counts the number of tweets in each class and returns the # of tweets from each class\n",
    "    count_zeros = (df == 0).sum().sum() #0 = hate speech\n",
    "    count_ones = (df == 1).sum().sum() #1 = offensive language\n",
    "    count_twos = (df == 2).sum().sum() #2 = normal text\n",
    "    \n",
    "    print(f\"Number of 0s: {count_zeros}\")\n",
    "    print(f\"Number of 1s: {count_ones}\")\n",
    "    print(f\"Number of 2s: {count_twos}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "043b024e-7ea7-4f38-99ca-15eb8f731506",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_file_optimized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#dft = pd.read_csv('2015testdata.csv') \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m result_df15 \u001b[38;5;241m=\u001b[39m process_file_optimized(dft, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2015 test\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(result_df15)\n\u001b[1;32m      5\u001b[0m scorecalc(result_df15)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_file_optimized' is not defined"
     ]
    }
   ],
   "source": [
    "# This is the general structure on how to run a dataset through the classification algorithm. Remember that the DF variable returned from process_file_optimized needs to be the same as the printed dataframe and the variable in the dataframe.\n",
    "result_df15 = process_file_optimized(dffive, \"2015 test\")\n",
    "print(result_dffive)\n",
    "\n",
    "scorecalc(result_dffive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69db7c94-266d-495f-8123-4133655be35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Scores for 2016 test\n",
      "0                         2\n",
      "1                         2\n",
      "2                         2\n",
      "3                         2\n",
      "4                         2\n",
      "...                     ...\n",
      "97558                     2\n",
      "97559                     2\n",
      "97560                     2\n",
      "97561                     2\n",
      "97562                     2\n",
      "\n",
      "[97563 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "dfsix = pd.read_csv('2016testdata.csv')\n",
    "result_df16 = process_file_optimized(dfsix, \"2016 test\")\n",
    "print(result_df16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b3f6a65-596b-4fdc-8c0b-faa2f146b386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 581\n",
      "Number of 1s: 8657\n",
      "Number of 2s: 88325\n"
     ]
    }
   ],
   "source": [
    "scorecalc(result_df16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3b51d18c-0e3f-40d1-9a6e-1812f92c4e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Scores for 2017 test\n",
      "0                          2\n",
      "1                          2\n",
      "2                          2\n",
      "3                          2\n",
      "4                          2\n",
      "...                      ...\n",
      "100689                     2\n",
      "100690                     2\n",
      "100691                     2\n",
      "100692                     2\n",
      "100693                     1\n",
      "\n",
      "[100694 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "dfseven = pd.read_csv('2017testdata.csv')\n",
    "result_df17 = process_file_optimized(dfseven, \"2017 test\")\n",
    "print(result_df17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8462891c-e628-453c-b268-e4746c01de96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 891\n",
      "Number of 1s: 9246\n",
      "Number of 2s: 90557\n"
     ]
    }
   ],
   "source": [
    "scorecalc(result_df17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc3d4e5d-5d17-4a71-a5f7-02f918eb1228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Scores for 2018 test\n",
      "0                         2\n",
      "1                         2\n",
      "2                         2\n",
      "3                         2\n",
      "4                         2\n",
      "...                     ...\n",
      "92719                     2\n",
      "92720                     1\n",
      "92721                     2\n",
      "92722                     1\n",
      "92723                     2\n",
      "\n",
      "[92724 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "dfeight = pd.read_csv('2018testdata.csv')\n",
    "result_df18 = process_file_optimized(dfeight, \"2018 test\")\n",
    "print(result_df18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c4d9343-0e7c-4168-ae09-b260d075f19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 629\n",
      "Number of 1s: 8160\n",
      "Number of 2s: 83935\n"
     ]
    }
   ],
   "source": [
    "scorecalc(result_df18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5745edd9-fb87-4a2f-9a81-18d77873af3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Scores for 2019 test\n",
      "0                         2\n",
      "1                         2\n",
      "2                         1\n",
      "3                         2\n",
      "4                         2\n",
      "...                     ...\n",
      "96621                     2\n",
      "96622                     2\n",
      "96623                     2\n",
      "96624                     2\n",
      "96625                     1\n",
      "\n",
      "[96626 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "dfnine = pd.read_csv('2019testdata.csv')\n",
    "result_df19 = process_file_optimized(dfnine, \"2019 test\")\n",
    "print(result_df19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f483e57b-f1ba-4288-866e-295190ecda06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 879\n",
      "Number of 1s: 10543\n",
      "Number of 2s: 85204\n"
     ]
    }
   ],
   "source": [
    "scorecalc(result_df19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aff5674b-49a4-4469-aea6-e1f903130751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Scores for 2020 test\n",
      "0                         2\n",
      "1                         2\n",
      "2                         2\n",
      "3                         2\n",
      "4                         2\n",
      "...                     ...\n",
      "97837                     2\n",
      "97838                     2\n",
      "97839                     2\n",
      "97840                     1\n",
      "97841                     1\n",
      "\n",
      "[97842 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "dfzero = pd.read_csv('2020testdata.csv')\n",
    "result_df20 = process_file_optimized(dfzero, \"2020 test\")\n",
    "print(result_df20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18eb3e0d-32ef-4e98-972d-e1b817c5fffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 994\n",
      "Number of 1s: 10339\n",
      "Number of 2s: 86509\n"
     ]
    }
   ],
   "source": [
    "scorecalc(result_df20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
